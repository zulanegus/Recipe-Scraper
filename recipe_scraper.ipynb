{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "TMR91NFzjwct"
      },
      "outputs": [],
      "source": [
        "#import required libraries \n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup \n",
        "import requests\n",
        "from urllib.request import Request, urlopen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhX_KWkaLQQO"
      },
      "source": [
        "# Scraping Data From [India Healthy Recipes Website](https://www.indianhealthyrecipes.com/chicken-biryani-recipe/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_N0W-eMLKWR"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "\n",
        "    url = \"https://www.indianhealthyrecipes.com/chicken-biryani-recipe/\"\n",
        "\n",
        "    source = requests.get(url) # connect to the website\n",
        "\n",
        "    soup = BeautifulSoup(source.text,'html.parser') # creeate Beautiful Soup Object\n",
        "\n",
        "    name = soup.find('h1').text # grab the recipe title\n",
        "\n",
        "    ingredients = soup.find('div', class_ = \"wprm-recipe-ingredients-container\").find_all('li') # grab the list of ingredients \n",
        "    ingredients = len(ingredients) # return the number of ingredients \n",
        "\n",
        "    appliances = soup.find('div', class_ = \"wprm-recipe-instructions-container\").get_text(strip = True).split('.')[8].split()[-4:] #grab the appliances used \n",
        "    appliances = ' '.join(appliances)\n",
        "\n",
        "    cook_time = soup.find('div', class_ = \"wprm-recipe-cook-time-container\").get_text() # grab the cooking time \n",
        "    cook_time = cook_time.replace('Cook Time25', '25')\n",
        "\n",
        "    prep_time = soup.find('div', class_ = \"wprm-recipe-prep-time-container\").get_text() # grab the prepation time\n",
        "    prep_time = prep_time.replace('Prep Time1', '1')\n",
        "    \n",
        "    #create a dictonary of the scraped data \n",
        "    dict_1 = {\"Recipe_Name\": name,\n",
        "          \"Number of Ingredients\": ingredients,\n",
        "          \"Appliances\": appliances,\n",
        "          \"Cook_Time\": cook_time,\n",
        "          \"Prep_Time\": prep_time}\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJns7dzCMFS1"
      },
      "source": [
        "# Scraping Data From [mmole.com Website](https://mmmole.com/receta-de-mole-poblano-y-enmoladas/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "fbCSBrUEMNT7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    url2 = 'https://mmmole.com/receta-de-mole-poblano-y-enmoladas/'\n",
        "    source2 = requests.get(url2)\n",
        "  \n",
        "\n",
        "    soup2 = BeautifulSoup(source2.text,'html.parser')\n",
        "\n",
        "    name2 = soup2.find('h1').get_text(strip = True)\n",
        "    \n",
        "    ingredients2 = soup2.find('div', class_ = \"wprm-recipe-ingredient-group\").find_all('li')\n",
        "    ingredients2 = len(ingredients2)\n",
        "\n",
        "    appliances2 = soup2.find('li', id=\"wprm-recipe-2113-step-1-0\").get_text(strip = True).split(' ')[0:4]\n",
        "    appliances2 = ' '.join(appliances2)\n",
        "\n",
        "    cook_time2 = soup2.find('span', class_=\"wprm-recipe-time\").text\n",
        "    \n",
        "\n",
        "    dict_2 = {\"Recipe_Name\": name2,\n",
        "      \"Number of Ingredients\": ingredients2,\n",
        "      \"Appliances\": appliances2,\n",
        "      \"Cook_Time\": cook_time2,\n",
        "      \"Prep_Time\": \" \"}\n",
        "    \n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yqX_97VMkQD"
      },
      "source": [
        "# Scraping Data From [Cookpad.com Website](https://cookpad.com/co/recetas/194594-como-hacer-tamales-santandereanos/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "1biSctVMbBSj"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "\n",
        "    url3 = 'https://cookpad.com/co/recetas/194594-como-hacer-tamales-santandereanos'\n",
        "    req = Request(url3 , headers={'User-Agent': 'Mozilla/5.0'})\n",
        "\n",
        "    source3 = urlopen(req).read()\n",
        "    soup3 = BeautifulSoup(source3, \"html.parser\")\n",
        "\n",
        "    name3 = soup3.find('h1').get_text(strip = True)\n",
        "\n",
        "    ingredients3 = soup3.find('div', class_ = \"ingredient-list\").find_all('li')\n",
        "    ingredients3 = len(ingredients3)\n",
        "\n",
        "    cook_time3 = soup.find('span', class_= \"px-rg\").get_text(strip = True)\n",
        "\n",
        "    dict_3 = {\"Recipe_Name\": name3,\n",
        "        \"Number of Ingredients\": ingredients3,\n",
        "        \"Appliances\": \" \",\n",
        "        \"Cook_Time\": cook_time3,\n",
        "        \"Prep_Time\": \" \"}\n",
        "      \n",
        "    \n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "recipe_df = pd.DataFrame([dict_1, dict_2, dict_3])  # create a dataframe \n",
        "recipe_df.to_csv(\"Recipe_DF.csv\") # export the dataframe as .csv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RSP2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
